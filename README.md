[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/joint-2d-3d-multi-task-learning-on-cityscapes/monocular-depth-estimation-on-cityscapes-3d)](https://paperswithcode.com/sota/monocular-depth-estimation-on-cityscapes-3d?p=joint-2d-3d-multi-task-learning-on-cityscapes)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/joint-2d-3d-multi-task-learning-on-cityscapes/3d-object-detection-on-cityscapes-3d)](https://paperswithcode.com/sota/3d-object-detection-on-cityscapes-3d?p=joint-2d-3d-multi-task-learning-on-cityscapes)
![Python 3.7](https://img.shields.io/badge/python-3.7-blue.svg)

# :fire: [CVPR2024, ICLR2023, ECCV2022] Powerful Multi-Task Models for Scene Understanding

##  :scroll: Introduction

This repository provides codes and models for three powerful multi-task models for scene understanding. Please check the following pages for details:

> [Hanrong Ye](https://sites.google.com/site/yhrspace/) and [Dan Xu](https://www.danxurgb.net/), [DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data](https://github.com/prismformore/Multi-Task-Transformer/tree/main/DiffusionMTL). 
> CVPR 2024
<p align="center">
  <img alt="img-name" src="https://github.com/prismformore/Multi-Task-Transformer/assets/14089338/5862c11f-cd1b-464c-b04e-28a729dde7d4" width="600">
</p>



> [Hanrong Ye](https://sites.google.com/site/yhrspace/) and [Dan Xu](https://www.danxurgb.net/), [TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding](https://github.com/prismformore/Multi-Task-Transformer/tree/main/TaskPrompter). 
> ICLR 2023
<p align="center">
  <img alt="img-name" src="https://user-images.githubusercontent.com/14089338/232197965-8936504d-8ce4-450b-a281-069f5c2c8205.gif" width="900">
</p>

> [Hanrong Ye](https://sites.google.com/site/yhrspace/) and [Dan Xu](https://www.danxurgb.net/), [Inverted Pyramid Multi-task Transformer for Dense Scene Understanding](https://github.com/prismformore/Multi-Task-Transformer/tree/main/InvPT). 
> ECCV 2022

<p align="center">
<img alt="img-name" src="https://user-images.githubusercontent.com/14089338/220043972-b3bfcc0d-d76e-4d34-8b20-d7c5d9f00a9f.gif" width="900">
<img alt="img-name" src="https://user-images.githubusercontent.com/14089338/220043986-291797a8-8994-4a54-846e-057e3778a972.gif" width="900">
</p>

# Cite
BibTex:
```
@InProceedings{invpt2022,
  title={Inverted Pyramid Multi-task Transformer for Dense Scene Understanding},
  author={Ye, Hanrong and Xu, Dan},
  booktitle={ECCV},
  year={2022}
}
@InProceedings{taskprompter2023,
  title={TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding},
  author={Ye, Hanrong and Xu, Dan},
  booktitle={ICLR},
  year={2023}
}
@article{ye2023invpt++,
  title={InvPT++: Inverted Pyramid Multi-Task Transformer for Visual Scene Understanding},
  author={Ye, Hanrong and Xu, Dan},
  journal={arXiv preprint arXiv:2306.04842},
  year={2023}
}
@InProceedings{diffusionmtl,
  title={DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data},
  author={Ye, Hanrong and Xu, Dan},
  booktitle={CVPR},
  year={2024}
}
```
Please do consider :star2: star our project to share with your community if you find this repository helpful!

# Contact
Please contact [Hanrong Ye](https://sites.google.com/site/yhrspace/) if any questions.

# Related Project
Few-show learning of multiple tasks: [Visual Token Matching](https://github.com/GitGyun/visual_token_matching) (ICLR 2023 Outstanding Paper Award)
